{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import mapping\n",
    "import pyproj\n",
    "import pandas as pd\n",
    "import sklearn as skl\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from lightgbm import LGBMClassifier\n",
    "from matplotlib.widgets import Cursor\n",
    "from matplotlib import animation\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a path to the data directory\n",
    "path_data = \"../../../dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the csv file with the data\n",
    "df = pd.read_csv(path_data + \"df_final.csv\")\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the dataset list_xy and list_xdimydim\n",
    "ds = xr.open_dataset( path_data + \"datacube_gps_train_2017_2018.nc\", decode_coords='all')\n",
    "#list_xdimydim = xr.open_dataset(path_data + \"list_xdimydim.nc\", decode_coords='all')\n",
    "ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_variables = ['ET_500m']#,\n",
    "\"\"\"                            'Fpar_500m',\n",
    "                            'u10',\n",
    "                            'v10',\n",
    "                            't2m',\n",
    "                            'tp',\n",
    "                            'LST_Day_1km',\n",
    "                            'LST_Night_1km',\n",
    "                            '_1_km_16_days_EVI']\"\"\"\n",
    "\n",
    "def get_df(the_ds, first_year=2015, last_year=2019, target_var='FireMask'):#, period_size=10, list_variables = []):\n",
    "        \"\"\"\n",
    "        This function returns a dataframe from the dataset in the given period,\n",
    "         dropping unnecessary variables and all NaN values\n",
    "        input:\n",
    "            the_ds: the dataset\n",
    "        output:\n",
    "            the_df: the dataframe\n",
    "        \"\"\"\n",
    "        \n",
    "        rus = RandomUnderSampler()\n",
    "        \n",
    "        # define an empty dataframe\n",
    "        the_df = pd.DataFrame()\n",
    "        \n",
    "        # Divide the dataset into every year\n",
    "        \n",
    "        for year in range(first_year, last_year+1):\n",
    "            \n",
    "            # Define the dataset for the year\n",
    "            the_df_year  = the_ds.sel(time=slice(str(year) + '-01-01', str(year) + '-12-30')).to_dataframe()\n",
    "\n",
    "            # drop the columns we don't need anymore\n",
    "            the_df_year = the_df_year.drop(columns = [\"crs\" , \"band\", \"spatial_ref\"])\n",
    "\n",
    "            # Reshape FireMask variable          \n",
    "                # drop the rows with NaN values\n",
    "            the_df_year = the_df_year.dropna()\n",
    "                # drop observations with FireMask = 0, 1 & 2 equivalent to NaN\n",
    "            the_df_year = the_df_year[(the_df_year.FireMask != 0) & (the_df_year.FireMask != 1) & (the_df_year.FireMask != 2)]\n",
    "\n",
    "            y_res = the_df_year[target_var].astype(int)\n",
    "\n",
    "            # Get y_res binary\n",
    "            y_res = y_res.replace([7, 8, 9], 1)\n",
    "            y_res = y_res.replace([3, 4, 5], 0)\n",
    "\n",
    "            # Add time x and y coordinates a new column\n",
    "            the_df_year = the_df_year.reset_index()\n",
    "                        \n",
    "            # Reshape the dataframe\n",
    "            the_df_year = rus.fit_resample(the_df_year, y_res)[0]\n",
    "                              \n",
    "            # Append the dataframe\n",
    "            the_df = the_df.append(the_df_year)\n",
    "            \n",
    "        return the_df\n",
    "\n",
    "df = get_df(ds, first_year=2017, last_year=2018, target_var='FireMask')#, period_size=3, list_variables = dynamic_variables)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the function to get a period days time selection\n",
    "def get_lastdays_mean_ds(the_ds, t=0, x=0, y=0, period_size=10, variable='u10'):\n",
    "    \"\"\"\n",
    "    This function returns a the mean value of the selected pixel and the selected period of time\n",
    "    input:\n",
    "        the_ds: the dataset\n",
    "        t: the time index\n",
    "        x: the x index\n",
    "        y: the y index\n",
    "        period_size: the size of the period\n",
    "        variable: the variable to be selected\n",
    "    output:\n",
    "        the mean value over the previous period_size days\n",
    "        of the selected pixel and the selected period of time\n",
    "    \"\"\"\n",
    "\n",
    "    mean_value = the_ds[variable].isel(x=x, y=y, time=slice(t-period_size-1, t-1)).mean(dim='time').values\n",
    "\n",
    "    return mean_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to loop over the dataset to fill the new variable\n",
    "dynamic_variables = ['ET_500m',\n",
    "                        'Fpar_500m',\n",
    "                        'u10',\n",
    "                        'v10',\n",
    "                        't2m',\n",
    "                        'tp',\n",
    "                        'LST_Day_1km',\n",
    "                        'LST_Night_1km',\n",
    "                        '_1_km_16_days_EVI']\n",
    "def fill_ds_mean(the_ds, period_size=10, list_variables = []):\n",
    "    \"\"\"\n",
    "    This function appends and fills the new variables of the dataset with the mean values,\n",
    "    then drops the old ones.\n",
    "    input:\n",
    "        the_ds: the dataset\n",
    "        period_size: the size of the period\n",
    "        list_variables: the variables to be selected\n",
    "    output:\n",
    "        the dataset with the new variables filled\n",
    "    \"\"\"\n",
    "    # Add a new variable to the dataset\n",
    "    for var in list_variables:\n",
    "        the_ds[var + '_last'+ str(period_size) + 'days' + '_mean'] = (('x', 'y',\n",
    "         'time'), np.zeros((the_ds.x.size, the_ds.y.size, the_ds.time.size)))\n",
    "\n",
    "    # loop over the dataset to fill the new variable\n",
    "    for var in list_variables:\n",
    "        for x in range(the_ds.x.size):\n",
    "            for y in range(the_ds.y.size):\n",
    "                for t in range(the_ds.time.size):\n",
    "                    the_ds[var + '_last'+ str(period_size) + 'days' + '_mean'].values[x, y,\n",
    "                    t] = get_lastdays_mean_ds(the_ds, t=t, x=x, y=y,\n",
    "                    period_size=period_size, variable=var)\n",
    "    \n",
    "    # drop the old variables\n",
    "    the_ds = the_ds.drop(dynamic_variables)\n",
    "\n",
    "   \n",
    "    return the_ds\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the dataframe\n",
    "df = ds.to_dataframe()\n",
    "\n",
    "# Reshape FireMask variable\n",
    "# drop observations with FireMask = 0, 1 & 2\n",
    "df = df[(df.FireMask != 0) & (df.FireMask != 1) & (df.FireMask != 2)]\n",
    "\n",
    "# drop the columns we don't need anymore\n",
    "df = df.drop(columns = [\"crs\" , \"band\", \"spatial_ref\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix : \n",
    "cor = df.corr() \n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(cor, square = True, cmap=\"coolwarm\", linewidths=0.5, annot=True, xticklabels='auto', yticklabels='auto',)\n",
    "#Pour choisr la couleur du heatmap : https://matplotlib.org/examples/color/colormaps_reference.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to get the correlation matrix and plot it\n",
    "def get_correlation_matrix(the_df, target_var='FireMask'):\n",
    "    \"\"\"\n",
    "    This function returns the correlation matrix of the dataframe\n",
    "    input:\n",
    "        the_df: the dataframe\n",
    "    output:\n",
    "        the correlation matrix\n",
    "    \"\"\"\n",
    "    # Correlation matrix : \n",
    "    cor = the_df.corr() \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    sns.heatmap(cor, square = True, cmap=\"coolwarm\", linewidths=0.5, annot=True, xticklabels='auto', yticklabels='auto',)\n",
    "    \n",
    "    \n",
    "    # get the correlation matrix of the target variable\n",
    "    #cor_target = abs(cor[target_var])\n",
    "    # select the features with a correlation higher than 0.5\n",
    "    #relevant_features = cor_target[cor_target>0.5]\n",
    "    # print the features\n",
    "    #print(relevant_features)\n",
    "    \n",
    "    return cor\n",
    "\n",
    "# get the correlation matrix\n",
    "cor = get_correlation_matrix(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We drop the columns that are not relevant for the model\n",
    "X = df.drop(columns = [\"time\", \"FireMask\"])\n",
    "y = df[[\"FireMask\"]].astype(int)\n",
    "# group 7, 8 and 9 in True\n",
    "#y = y.replace([7, 8, 9], 1)\n",
    "# group 3, 4 and 5 in False\n",
    "#y = y.replace([3, 4, 5], 0)\n",
    "#y = y.replace(9, 7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "# We drop the columns that are not relevant for the model\n",
    "X = df\n",
    "y = df[[\"FireMask\"]].astype(int)\n",
    "# group 7, 8 and 9 in True\n",
    "y = y.replace([7, 8, 9], 1)\n",
    "# group 3, 4 and 5 in False\n",
    "y = y.replace([3, 4, 5], 0)\n",
    "#y = y.replace(9, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Undersampling the dataframes to balance the classes\n",
    "rus = RandomUnderSampler()\n",
    "X_res, y_res = rus.fit_resample(X, y)\n",
    "#to remark that X_res, y_res lose their original index\n",
    "#X_res\n",
    "#rus.fit_resample(X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, define the models we want to use\n",
    "# We use the default parameters for each model\n",
    "# We use the same random state for each model to be able to compare them\n",
    "# We use the class_weight parameter to balance the classes\n",
    "# We use the max_iter parameter to avoid convergence warnings\n",
    "# We use the n_estimators parameter to avoid convergence warnings\n",
    "# We use the max_depth parameter to avoid convergence warnings\n",
    "# We use the l1_ratio parameter to avoid convergence warnings\n",
    "\n",
    "# Download the libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Linear regression, k nearest neighbors, random forest, xgboost, lightgbm \n",
    "model_LR = skl.linear_model.LogisticRegression(C=0.05, l1_ratio=None, max_iter=10000)\n",
    "model_KNN = skl.neighbors.KNeighborsClassifier()\n",
    "model_RF = skl.ensemble.RandomForestClassifier(n_estimators=100, max_depth=2)\n",
    "model_XGB = XGBClassifier(n_estimators=100, max_depth=2, use_label_encoder=False)\n",
    "model_LGBM = LGBMClassifier(n_estimators=100, max_depth=2)\n",
    "\n",
    "# put all those models in a list\n",
    "models = [model_LR, model_KNN, model_RF, model_XGB, model_LGBM]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the libraries for the cross validation\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# define a function to perform cross validation for the given models\n",
    "def cross_validation(models, X, y, n_splits=10, random_state=71, stratified=True):\n",
    "    \"\"\"\n",
    "    This function performs cross validation for the given models\n",
    "    input:\n",
    "        models: the models to be evaluated\n",
    "        X: the features\n",
    "        y: the target\n",
    "        n_splits: the number of splits\n",
    "        random_state: the random state\n",
    "    output:\n",
    "        a dataframe with the results\n",
    "    \"\"\"\n",
    "    # create a dataframe to store the results\n",
    "    results = pd.DataFrame(columns=['model', 'accuracy', 'precision', 'recall', 'f1'])\n",
    "    # Create conditional statement to check if stratified or not\n",
    "    if stratified:\n",
    "        # create a stratified k-fold object\n",
    "        skf = StratifiedKFold(n_splits=n_splits, shuffle=False) #, random_state=random_state)\n",
    "    else:\n",
    "        # create a non stratified k-fold object\n",
    "        skf = KFold(n_splits=n_splits, shuffle=False) #, random_state=random_state)\n",
    "    # loop over the folds\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        # split the data\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        # loop over the models\n",
    "        for model in models:\n",
    "            # fit the model\n",
    "            time_0 = datetime.datetime.now()\n",
    "            model.fit(X_train, np.ravel(y_train))\n",
    "            time_1 = datetime.datetime.now()\n",
    "            # predict the target\n",
    "            y_pred = model.predict(X_test)\n",
    "            # compute the accuracy\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            # compute the precision\n",
    "            precision = classification_report(y_test, y_pred, output_dict=True)['1']['precision']\n",
    "            # compute the recall\n",
    "            recall = classification_report(y_test, y_pred, output_dict=True)['1']['recall']\n",
    "            # compute the f1 score\n",
    "            f1 = classification_report(y_test, y_pred, output_dict=True)['1']['f1-score']\n",
    "            # compute the time to fit the model in seconds\n",
    "            time_fit = (time_1 - time_0).total_seconds()\n",
    "\n",
    "            # store the results in the dataframe sorted by accuracy\n",
    "            results = results.append({'model': model.__class__.__name__,\n",
    "                                      'accuracy': accuracy,\n",
    "                                      'precision': precision,\n",
    "                                      'recall': recall,\n",
    "                                      'f1': f1,\n",
    "                                      'Time to fit': time_fit}, ignore_index=True)\n",
    "\n",
    "            # sort the results by accuracy\n",
    "            # results = results.sort_values(by='accuracy', ascending=False)\n",
    "\n",
    "            # group the results by model\n",
    "            results = results.groupby('model').mean().reset_index().sort_values(by='accuracy',\n",
    "                             ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # return the dataframe\n",
    "    return results\n",
    "\n",
    "# perform the 10-fold cross validation\n",
    "results = cross_validation(models, X, y, n_splits=10, random_state=71, stratified=False)\n",
    "results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-fold cross validation on Logistic Regression model\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "model_LR = skl.linear_model.LogisticRegression(C=0.05, l1_ratio=None, max_iter=10000)\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=71)\n",
    "i = 1\n",
    "Accuracy_array = []\n",
    "for train_index, test_index in kf.split(X_res, y_res):\n",
    "    X_train, X_test = X_res.iloc[train_index], X_res.iloc[test_index]\n",
    "    y_train, y_test = y_res.iloc[train_index], y_res.iloc[test_index]\n",
    "     \n",
    "    #Train the model\n",
    "    model_LR.fit(X_train, np.ravel(y_train,order='C')) #Training the model \n",
    "    \n",
    "    #Evaluate the acuracy of the model\n",
    "    print(f\"Accuracy for the fold no. {i} on the test set: {accuracy_score(y_test, model_LR.predict(X_test))}, doublecheck: {model_LR.score(X_test,y_test)}\")\n",
    "    Accuracy_array.append(accuracy_score(y_test, model_LR.predict(X_test)))\n",
    "    i += 1\n",
    "Accuracy_array\n",
    "# Compute the mean accuracy\n",
    "print(f\"Mean accuracy: {np.mean(Accuracy_array)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-fold cross validation on K-Nearst Neighbors model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model_KNN = skl.neighbors.KNeighborsClassifier()\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=71)\n",
    "i = 1\n",
    "Accuracy_array = []\n",
    "for train_index, test_index in kf.split(X_res, y_res):\n",
    "    X_train, X_test = X_res.iloc[train_index], X_res.iloc[test_index]\n",
    "    y_train, y_test = y_res.iloc[train_index], y_res.iloc[test_index]\n",
    "     \n",
    "    #Train the model\n",
    "    model_KNN.fit(X_train, np.ravel(y_train,order='C')) #Training the model \n",
    "    \n",
    "    #Evaluate the acuracy of the model\n",
    "    print(f\"Accuracy for the fold no. {i} on the test set: {accuracy_score(y_test, model_LR.predict(X_test))}, doublecheck: {model_LR.score(X_test,y_test)}\")\n",
    "    Accuracy_array.append(accuracy_score(y_test, model_LR.predict(X_test)))\n",
    "    i += 1\n",
    "\n",
    "# Compute the mean accuracy\n",
    "print(f\"Mean accuracy: {np.mean(Accuracy_array)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-fold cross validation on random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "model_RF = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=71)\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=71)\n",
    "i = 1\n",
    "Accuracy_array = []\n",
    "for train_index, test_index in kf.split(X_res, y_res):\n",
    "    print('Fold: {}'.format(i))\n",
    "    X_train, X_test = X_res.iloc[train_index], X_res.iloc[test_index]\n",
    "    y_train, y_test = y_res.iloc[train_index], y_res.iloc[test_index]\n",
    "\n",
    "    #Train the model\n",
    "    model_RF.fit(X_train, np.ravel(y_train, order='C'))\n",
    "    \n",
    "    #Predict the response for test dataset\n",
    "    print(f\"Accuracy for the fold no. {i} on the test set: {accuracy_score(y_test, model_RF.predict(X_test))}, doublecheck: {model_RF.score(X_test,y_test)}\")\n",
    "    Accuracy_array.append(accuracy_score(y_test, model_RF.predict(X_test)))\n",
    "    i += 1\n",
    "    \n",
    "# Compute the mean accuracy\n",
    "print(f\"Mean accuracy: {np.mean(Accuracy_array)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-fold cross validation on random XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "model_XGB = XGBClassifier(n_estimators=100, max_depth=6, use_label_encoder=False)\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=71)\n",
    "i = 1\n",
    "Accuracy_array = []\n",
    "for train_index, test_index in kf.split(X_res, y_res):\n",
    "    print('Fold: {}'.format(i))\n",
    "    X_train, X_test = X_res.iloc[train_index], X_res.iloc[test_index]\n",
    "    y_train, y_test = y_res.iloc[train_index], y_res.iloc[test_index]\n",
    "\n",
    "    #Train the model\n",
    "    model_XGB.fit(X_train, np.ravel(y_train, order='C'))\n",
    "    \n",
    "    #Predict the response for test dataset\n",
    "    print(f\"Accuracy for the fold no. {i} on the test set: {accuracy_score(y_test, model_XGB.predict(X_test))}, doublecheck: {model_XGB.score(X_test,y_test)}\")\n",
    "    Accuracy_array.append(accuracy_score(y_test, model_XGB.predict(X_test)))\n",
    "    i += 1\n",
    "\n",
    "# Compute the mean accuracy\n",
    "print(f\"Mean accuracy: {np.mean(Accuracy_array)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-fold cross validation on random lightgbm\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "model_LGBM = LGBMClassifier(n_estimators=100, max_depth=2, random_state=71)\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=71)\n",
    "i = 1\n",
    "Accuracy_array = []\n",
    "for train_index, test_index in kf.split(X_res, y_res):\n",
    "    print('Fold: {}'.format(i))\n",
    "    X_train, X_test = X_res.iloc[train_index], X_res.iloc[test_index]\n",
    "    y_train, y_test = y_res.iloc[train_index], y_res.iloc[test_index]\n",
    "\n",
    "    #Train the model\n",
    "    model_LGBM.fit(X_train, np.ravel(y_train, order='C'))\n",
    "    \n",
    "    #Predict the response for test dataset\n",
    "    print(f\"Accuracy for the fold no. {i} on the test set: {accuracy_score(y_test, model_LGBM.predict(X_test))}, doublecheck: {model_LGBM.score(X_test,y_test)}\")\n",
    "    Accuracy_array.append(accuracy_score(y_test, model_LGBM.predict(X_test)))\n",
    "    i += 1\n",
    "\n",
    "# Compute the mean accuracy\n",
    "print(f\"Mean accuracy: {np.mean(Accuracy_array)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get time column\n",
    "time_col = df['time']\n",
    "# get first 4 digits of time column\n",
    "time_col = time_col.apply(lambda x: str(x)[:4])\n",
    "# convert to int\n",
    "time_col = time_col.astype(int)\n",
    "time_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train on 2010 to 2017 and test on 2018 to 2020\n",
    "df_train = df[df['time'].apply(lambda x: str(x)[:4]).astype(int) < 2018]\n",
    "df_test = df[df['time'].apply(lambda x: str(x)[:4]).astype(int) >= 2018]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path_data + \"df_final.csv\", parse_dates=[\"time\"])\n",
    "# add a column for the month\n",
    "df['month'] = df['time'].dt.month\n",
    "# add a column for the trimester\n",
    "df['trimester'] = df['time'].dt.quarter\n",
    "# Split the data into train and test\n",
    "df_train = df[df[\"time\"] < \"2018-01-01\"]\n",
    "df_test = df[df[\"time\"] >= \"2018-01-01\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def fit_lgbm_model(the_df_train, n_estimators=100, max_depth=2, path_data=\"\"):\n",
    "    \"\"\"\n",
    "    This function fits a lgmb model\n",
    "    input:\n",
    "        the_df_train: the dataframe\n",
    "        n_estimators: the number of estimators\n",
    "        max_depth: the maximum depth\n",
    "        path_data: the path where to save the pickle file\n",
    "    output:\n",
    "        the model\n",
    "    \"\"\"\n",
    "    # define the model\n",
    "    model = LGBMClassifier(n_estimators=n_estimators, max_depth=max_depth)\n",
    "    # define the features and the target\n",
    "    X_train = the_df_train.drop(['time','FireMask'], axis=1)\n",
    "    y_train = the_df_train['FireMask'].astype(int)\n",
    "    # fit the model\n",
    "    time_start = datetime.datetime.now()\n",
    "    model.fit(X_train, y_train)\n",
    "    time_end = datetime.datetime.now()\n",
    "    # Add the time as model attribute\n",
    "    model.time = (time_end - time_start).total_seconds()\n",
    "    # save the pickle file\n",
    "    #pickle.dump(model, open('model_lgbm.pkl', 'wb'))\n",
    "    # generate the pickle file\n",
    "    pickle.dump(model, open(path_data + 'model_lgbm.pkl', 'wb'))\n",
    "    # return the pickle\n",
    "    return model\n",
    "\n",
    "lgbm_model = fit_lgbm_model(df_train, n_estimators=100, max_depth=2, path_data=path_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>FireMask</th>\n",
       "      <th>FireMask_pred</th>\n",
       "      <th>FireMask_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22558</th>\n",
       "      <td>2018-08-17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.299340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22559</th>\n",
       "      <td>2018-08-18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.299340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22560</th>\n",
       "      <td>2018-08-19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.299340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22561</th>\n",
       "      <td>2018-08-20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.315055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22562</th>\n",
       "      <td>2018-08-21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.315055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29177</th>\n",
       "      <td>2020-11-09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.148010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29178</th>\n",
       "      <td>2020-05-16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.201505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29179</th>\n",
       "      <td>2020-02-13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.658058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29180</th>\n",
       "      <td>2020-02-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.265288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29181</th>\n",
       "      <td>2020-08-11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.132864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6624 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            time  FireMask  FireMask_pred  FireMask_proba\n",
       "22558 2018-08-17         1              0        0.299340\n",
       "22559 2018-08-18         1              0        0.299340\n",
       "22560 2018-08-19         1              0        0.299340\n",
       "22561 2018-08-20         1              0        0.315055\n",
       "22562 2018-08-21         1              0        0.315055\n",
       "...          ...       ...            ...             ...\n",
       "29177 2020-11-09         0              0        0.148010\n",
       "29178 2020-05-16         0              0        0.201505\n",
       "29179 2020-02-13         0              1        0.658058\n",
       "29180 2020-02-05         0              0        0.265288\n",
       "29181 2020-08-11         0              0        0.132864\n",
       "\n",
       "[6624 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_lgbm_model(the_df_test, model):\n",
    "    \"\"\"\n",
    "    This function predicts the lgbm model\n",
    "    input:\n",
    "        the_df_test: the tet dataframe\n",
    "        model: the model\n",
    "    output:\n",
    "        the predictions\n",
    "    \"\"\"\n",
    "    # define the features\n",
    "    X_test = the_df_test.drop(['time','FireMask'], axis=1)\n",
    "    # predict the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    # give the perobabilities of the predictions\n",
    "    y_pred_proba = model.predict_proba(X_test)\n",
    "    # Add the predictions and the probabilities to the dataframe\n",
    "    #the_df_test['FireMask_pred'] = y_pred\n",
    "    #the_df_test['FireMask_proba'] = y_pred_proba[:,1]\n",
    "\n",
    "    # Stack the prediction with the time and target\n",
    "    the_df_pred = pd.DataFrame({\"time\":the_df_test[\"time\"], \"FireMask\": the_df_test[\"FireMask\"].astype(int),\n",
    "                                \"FireMask_pred\": y_pred, \"FireMask_proba\": y_pred_proba[:, 1]})\n",
    "    \n",
    "    # return the the dataframe\n",
    "    return the_df_pred\n",
    "\n",
    "df_pred = predict_lgbm_model(df_test, lgbm_model)\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = \"../../../dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the index\n",
    "#df_pred.reset_index(inplace=True, drop=False)\n",
    "#df_test.reset_index(inplace=True, drop=False)\n",
    "#df_pred.drop['time','FireMask'], axis=1)\n",
    "#df.drop(['time','FireMask'])\n",
    "# merge the two dataframes\n",
    "#df_model = df_test.merge(df_pred, on='index', how='left')\n",
    "\n",
    "# save the dataframe to csv\n",
    "df_model.to_csv(path_data + \"df_model.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time to fit [s]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.783967</td>\n",
       "      <td>0.808664</td>\n",
       "      <td>0.743961</td>\n",
       "      <td>0.774965</td>\n",
       "      <td>0.456996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model  accuracy  precision    recall        f1  time to fit [s]\n",
       "0  LGBMClassifier  0.783967   0.808664  0.743961  0.774965         0.456996"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the libraries\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, classification_report\n",
    "\n",
    "# define a function to plot accuracy, precision, recall, f1-score\n",
    "def plot_metrics(model, y_test, y_pred):\n",
    "    \"\"\"\n",
    "    This function plots the accuracy, precision, recall, f1-score\n",
    "    input:\n",
    "        y_test: the test target\n",
    "        y_pred: the predictions\n",
    "    output:\n",
    "        None\n",
    "    \"\"\"\n",
    "    results = pd.DataFrame(columns=['model', 'accuracy', 'precision', 'recall', 'f1'])\n",
    "    # compute the metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    # plot the metrics\n",
    "    results = results.append({'model': model.__class__.__name__,\n",
    "                                      'accuracy': accuracy,\n",
    "                                      'precision': precision,\n",
    "                                      'recall': recall,\n",
    "                                      'f1': f1,\n",
    "                                      'time to fit [s]': model.time\n",
    "                                      }, ignore_index=True)\n",
    "    return results\n",
    "\n",
    "resultas = plot_metrics(lgbm_model, df_pred['FireMask'], df_pred['FireMask_pred'].astype(int))\n",
    "resultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe to csv\n",
    "df_pred.to_csv(path_data + \"df_pred.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>time</th>\n",
       "      <th>density</th>\n",
       "      <th>First_Day</th>\n",
       "      <th>Last_Day</th>\n",
       "      <th>Burn_Date</th>\n",
       "      <th>FireMask</th>\n",
       "      <th>ET_500m_mean</th>\n",
       "      <th>Fpar_500m_mean</th>\n",
       "      <th>u10_mean</th>\n",
       "      <th>v10_mean</th>\n",
       "      <th>t2m_mean</th>\n",
       "      <th>tp_mean</th>\n",
       "      <th>LST_Day_1km_mean</th>\n",
       "      <th>LST_Night_1km_mean</th>\n",
       "      <th>_1_km_16_days_EVI_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22558</th>\n",
       "      <td>4.337576</td>\n",
       "      <td>44.430909</td>\n",
       "      <td>2018-08-17</td>\n",
       "      <td>65.063034</td>\n",
       "      <td>207.411290</td>\n",
       "      <td>279.903226</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.230000</td>\n",
       "      <td>0.584072</td>\n",
       "      <td>0.419922</td>\n",
       "      <td>-1.000133</td>\n",
       "      <td>293.199289</td>\n",
       "      <td>0.004510</td>\n",
       "      <td>301.407863</td>\n",
       "      <td>289.563687</td>\n",
       "      <td>0.380487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22559</th>\n",
       "      <td>4.337576</td>\n",
       "      <td>44.430909</td>\n",
       "      <td>2018-08-18</td>\n",
       "      <td>65.063034</td>\n",
       "      <td>208.483871</td>\n",
       "      <td>280.709677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.100002</td>\n",
       "      <td>0.585918</td>\n",
       "      <td>0.456385</td>\n",
       "      <td>-1.454020</td>\n",
       "      <td>292.898217</td>\n",
       "      <td>0.004733</td>\n",
       "      <td>301.139173</td>\n",
       "      <td>289.720516</td>\n",
       "      <td>0.382837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22560</th>\n",
       "      <td>4.337576</td>\n",
       "      <td>44.430909</td>\n",
       "      <td>2018-08-19</td>\n",
       "      <td>65.063034</td>\n",
       "      <td>209.556452</td>\n",
       "      <td>281.516129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.850001</td>\n",
       "      <td>0.587551</td>\n",
       "      <td>0.431329</td>\n",
       "      <td>-1.913773</td>\n",
       "      <td>292.856045</td>\n",
       "      <td>0.004273</td>\n",
       "      <td>301.387495</td>\n",
       "      <td>290.000703</td>\n",
       "      <td>0.385432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22561</th>\n",
       "      <td>4.337576</td>\n",
       "      <td>44.430909</td>\n",
       "      <td>2018-08-20</td>\n",
       "      <td>65.063034</td>\n",
       "      <td>210.629032</td>\n",
       "      <td>282.322581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.600000</td>\n",
       "      <td>0.588971</td>\n",
       "      <td>0.459216</td>\n",
       "      <td>-1.988419</td>\n",
       "      <td>293.172901</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>301.535495</td>\n",
       "      <td>290.404703</td>\n",
       "      <td>0.388272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22562</th>\n",
       "      <td>4.337576</td>\n",
       "      <td>44.430909</td>\n",
       "      <td>2018-08-21</td>\n",
       "      <td>65.063034</td>\n",
       "      <td>211.701613</td>\n",
       "      <td>283.129032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.350000</td>\n",
       "      <td>0.590178</td>\n",
       "      <td>0.499901</td>\n",
       "      <td>-2.060565</td>\n",
       "      <td>293.591260</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>301.630000</td>\n",
       "      <td>290.748497</td>\n",
       "      <td>0.391357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29177</th>\n",
       "      <td>6.368977</td>\n",
       "      <td>44.678641</td>\n",
       "      <td>2020-11-09</td>\n",
       "      <td>1.219522</td>\n",
       "      <td>303.233333</td>\n",
       "      <td>330.133333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3276.500000</td>\n",
       "      <td>0.210865</td>\n",
       "      <td>-0.744626</td>\n",
       "      <td>-0.512833</td>\n",
       "      <td>274.738078</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>282.273217</td>\n",
       "      <td>272.741976</td>\n",
       "      <td>0.142431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29178</th>\n",
       "      <td>5.308685</td>\n",
       "      <td>43.519256</td>\n",
       "      <td>2020-05-16</td>\n",
       "      <td>62.826794</td>\n",
       "      <td>117.935484</td>\n",
       "      <td>190.032258</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.600000</td>\n",
       "      <td>0.600984</td>\n",
       "      <td>-0.620881</td>\n",
       "      <td>0.019610</td>\n",
       "      <td>288.015295</td>\n",
       "      <td>0.002085</td>\n",
       "      <td>296.151572</td>\n",
       "      <td>288.335298</td>\n",
       "      <td>0.364459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29179</th>\n",
       "      <td>4.377214</td>\n",
       "      <td>44.787643</td>\n",
       "      <td>2020-02-13</td>\n",
       "      <td>3.489132</td>\n",
       "      <td>35.017241</td>\n",
       "      <td>87.482759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3276.500000</td>\n",
       "      <td>0.407908</td>\n",
       "      <td>1.204479</td>\n",
       "      <td>-0.460502</td>\n",
       "      <td>276.489115</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>279.911783</td>\n",
       "      <td>275.180564</td>\n",
       "      <td>0.192178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29180</th>\n",
       "      <td>5.724875</td>\n",
       "      <td>44.193087</td>\n",
       "      <td>2020-02-05</td>\n",
       "      <td>1.912674</td>\n",
       "      <td>15.413793</td>\n",
       "      <td>77.206897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.139999</td>\n",
       "      <td>0.514080</td>\n",
       "      <td>0.833045</td>\n",
       "      <td>-1.375424</td>\n",
       "      <td>276.273282</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>283.015223</td>\n",
       "      <td>275.484973</td>\n",
       "      <td>0.332222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29181</th>\n",
       "      <td>5.863604</td>\n",
       "      <td>44.371453</td>\n",
       "      <td>2020-08-11</td>\n",
       "      <td>3.482120</td>\n",
       "      <td>201.169355</td>\n",
       "      <td>271.491935</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.660000</td>\n",
       "      <td>0.524723</td>\n",
       "      <td>0.301766</td>\n",
       "      <td>-0.870711</td>\n",
       "      <td>292.560683</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>306.791210</td>\n",
       "      <td>292.312144</td>\n",
       "      <td>0.322469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6624 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              x          y       time    density   First_Day    Last_Day  \\\n",
       "22558  4.337576  44.430909 2018-08-17  65.063034  207.411290  279.903226   \n",
       "22559  4.337576  44.430909 2018-08-18  65.063034  208.483871  280.709677   \n",
       "22560  4.337576  44.430909 2018-08-19  65.063034  209.556452  281.516129   \n",
       "22561  4.337576  44.430909 2018-08-20  65.063034  210.629032  282.322581   \n",
       "22562  4.337576  44.430909 2018-08-21  65.063034  211.701613  283.129032   \n",
       "...         ...        ...        ...        ...         ...         ...   \n",
       "29177  6.368977  44.678641 2020-11-09   1.219522  303.233333  330.133333   \n",
       "29178  5.308685  43.519256 2020-05-16  62.826794  117.935484  190.032258   \n",
       "29179  4.377214  44.787643 2020-02-13   3.489132   35.017241   87.482759   \n",
       "29180  5.724875  44.193087 2020-02-05   1.912674   15.413793   77.206897   \n",
       "29181  5.863604  44.371453 2020-08-11   3.482120  201.169355  271.491935   \n",
       "\n",
       "       Burn_Date  FireMask  ET_500m_mean  Fpar_500m_mean  u10_mean  v10_mean  \\\n",
       "22558        0.0       1.0     16.230000        0.584072  0.419922 -1.000133   \n",
       "22559        0.0       1.0     16.100002        0.585918  0.456385 -1.454020   \n",
       "22560        0.0       1.0     15.850001        0.587551  0.431329 -1.913773   \n",
       "22561        0.0       1.0     15.600000        0.588971  0.459216 -1.988419   \n",
       "22562        0.0       1.0     15.350000        0.590178  0.499901 -2.060565   \n",
       "...          ...       ...           ...             ...       ...       ...   \n",
       "29177        0.0       0.0   3276.500000        0.210865 -0.744626 -0.512833   \n",
       "29178        0.0       0.0     22.600000        0.600984 -0.620881  0.019610   \n",
       "29179        0.0       0.0   3276.500000        0.407908  1.204479 -0.460502   \n",
       "29180        0.0       0.0      7.139999        0.514080  0.833045 -1.375424   \n",
       "29181        0.0       0.0     19.660000        0.524723  0.301766 -0.870711   \n",
       "\n",
       "         t2m_mean   tp_mean  LST_Day_1km_mean  LST_Night_1km_mean  \\\n",
       "22558  293.199289  0.004510        301.407863          289.563687   \n",
       "22559  292.898217  0.004733        301.139173          289.720516   \n",
       "22560  292.856045  0.004273        301.387495          290.000703   \n",
       "22561  293.172901  0.001606        301.535495          290.404703   \n",
       "22562  293.591260  0.001606        301.630000          290.748497   \n",
       "...           ...       ...               ...                 ...   \n",
       "29177  274.738078  0.000372        282.273217          272.741976   \n",
       "29178  288.015295  0.002085        296.151572          288.335298   \n",
       "29179  276.489115  0.000287        279.911783          275.180564   \n",
       "29180  276.273282  0.001132        283.015223          275.484973   \n",
       "29181  292.560683  0.000054        306.791210          292.312144   \n",
       "\n",
       "       _1_km_16_days_EVI_mean  \n",
       "22558                0.380487  \n",
       "22559                0.382837  \n",
       "22560                0.385432  \n",
       "22561                0.388272  \n",
       "22562                0.391357  \n",
       "...                       ...  \n",
       "29177                0.142431  \n",
       "29178                0.364459  \n",
       "29179                0.192178  \n",
       "29180                0.332222  \n",
       "29181                0.322469  \n",
       "\n",
       "[6624 rows x 17 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luigi\\anaconda3\\envs\\tamere_env\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "c:\\Users\\luigi\\anaconda3\\envs\\tamere_env\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>time</th>\n",
       "      <th>density</th>\n",
       "      <th>First_Day</th>\n",
       "      <th>Last_Day</th>\n",
       "      <th>Burn_Date</th>\n",
       "      <th>FireMask</th>\n",
       "      <th>ET_500m_mean</th>\n",
       "      <th>Fpar_500m_mean</th>\n",
       "      <th>u10_mean</th>\n",
       "      <th>v10_mean</th>\n",
       "      <th>t2m_mean</th>\n",
       "      <th>tp_mean</th>\n",
       "      <th>LST_Day_1km_mean</th>\n",
       "      <th>LST_Night_1km_mean</th>\n",
       "      <th>_1_km_16_days_EVI_mean</th>\n",
       "      <th>FireMask_pred</th>\n",
       "      <th>FireMask_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22558</th>\n",
       "      <td>4.337576</td>\n",
       "      <td>44.430909</td>\n",
       "      <td>2018-08-17</td>\n",
       "      <td>65.063034</td>\n",
       "      <td>207.411290</td>\n",
       "      <td>279.903226</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.230000</td>\n",
       "      <td>0.584072</td>\n",
       "      <td>0.419922</td>\n",
       "      <td>-1.000133</td>\n",
       "      <td>293.199289</td>\n",
       "      <td>0.004510</td>\n",
       "      <td>301.407863</td>\n",
       "      <td>289.563687</td>\n",
       "      <td>0.380487</td>\n",
       "      <td>0</td>\n",
       "      <td>0.286378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22559</th>\n",
       "      <td>4.337576</td>\n",
       "      <td>44.430909</td>\n",
       "      <td>2018-08-18</td>\n",
       "      <td>65.063034</td>\n",
       "      <td>208.483871</td>\n",
       "      <td>280.709677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.100002</td>\n",
       "      <td>0.585918</td>\n",
       "      <td>0.456385</td>\n",
       "      <td>-1.454020</td>\n",
       "      <td>292.898217</td>\n",
       "      <td>0.004733</td>\n",
       "      <td>301.139173</td>\n",
       "      <td>289.720516</td>\n",
       "      <td>0.382837</td>\n",
       "      <td>0</td>\n",
       "      <td>0.286378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22560</th>\n",
       "      <td>4.337576</td>\n",
       "      <td>44.430909</td>\n",
       "      <td>2018-08-19</td>\n",
       "      <td>65.063034</td>\n",
       "      <td>209.556452</td>\n",
       "      <td>281.516129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.850001</td>\n",
       "      <td>0.587551</td>\n",
       "      <td>0.431329</td>\n",
       "      <td>-1.913773</td>\n",
       "      <td>292.856045</td>\n",
       "      <td>0.004273</td>\n",
       "      <td>301.387495</td>\n",
       "      <td>290.000703</td>\n",
       "      <td>0.385432</td>\n",
       "      <td>0</td>\n",
       "      <td>0.286378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22561</th>\n",
       "      <td>4.337576</td>\n",
       "      <td>44.430909</td>\n",
       "      <td>2018-08-20</td>\n",
       "      <td>65.063034</td>\n",
       "      <td>210.629032</td>\n",
       "      <td>282.322581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.600000</td>\n",
       "      <td>0.588971</td>\n",
       "      <td>0.459216</td>\n",
       "      <td>-1.988419</td>\n",
       "      <td>293.172901</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>301.535495</td>\n",
       "      <td>290.404703</td>\n",
       "      <td>0.388272</td>\n",
       "      <td>0</td>\n",
       "      <td>0.302589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22562</th>\n",
       "      <td>4.337576</td>\n",
       "      <td>44.430909</td>\n",
       "      <td>2018-08-21</td>\n",
       "      <td>65.063034</td>\n",
       "      <td>211.701613</td>\n",
       "      <td>283.129032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.350000</td>\n",
       "      <td>0.590178</td>\n",
       "      <td>0.499901</td>\n",
       "      <td>-2.060565</td>\n",
       "      <td>293.591260</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>301.630000</td>\n",
       "      <td>290.748497</td>\n",
       "      <td>0.391357</td>\n",
       "      <td>0</td>\n",
       "      <td>0.302589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29177</th>\n",
       "      <td>6.368977</td>\n",
       "      <td>44.678641</td>\n",
       "      <td>2020-11-09</td>\n",
       "      <td>1.219522</td>\n",
       "      <td>303.233333</td>\n",
       "      <td>330.133333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3276.500000</td>\n",
       "      <td>0.210865</td>\n",
       "      <td>-0.744626</td>\n",
       "      <td>-0.512833</td>\n",
       "      <td>274.738078</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>282.273217</td>\n",
       "      <td>272.741976</td>\n",
       "      <td>0.142431</td>\n",
       "      <td>0</td>\n",
       "      <td>0.143328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29178</th>\n",
       "      <td>5.308685</td>\n",
       "      <td>43.519256</td>\n",
       "      <td>2020-05-16</td>\n",
       "      <td>62.826794</td>\n",
       "      <td>117.935484</td>\n",
       "      <td>190.032258</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.600000</td>\n",
       "      <td>0.600984</td>\n",
       "      <td>-0.620881</td>\n",
       "      <td>0.019610</td>\n",
       "      <td>288.015295</td>\n",
       "      <td>0.002085</td>\n",
       "      <td>296.151572</td>\n",
       "      <td>288.335298</td>\n",
       "      <td>0.364459</td>\n",
       "      <td>0</td>\n",
       "      <td>0.211722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29179</th>\n",
       "      <td>4.377214</td>\n",
       "      <td>44.787643</td>\n",
       "      <td>2020-02-13</td>\n",
       "      <td>3.489132</td>\n",
       "      <td>35.017241</td>\n",
       "      <td>87.482759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3276.500000</td>\n",
       "      <td>0.407908</td>\n",
       "      <td>1.204479</td>\n",
       "      <td>-0.460502</td>\n",
       "      <td>276.489115</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>279.911783</td>\n",
       "      <td>275.180564</td>\n",
       "      <td>0.192178</td>\n",
       "      <td>1</td>\n",
       "      <td>0.644748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29180</th>\n",
       "      <td>5.724875</td>\n",
       "      <td>44.193087</td>\n",
       "      <td>2020-02-05</td>\n",
       "      <td>1.912674</td>\n",
       "      <td>15.413793</td>\n",
       "      <td>77.206897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.139999</td>\n",
       "      <td>0.514080</td>\n",
       "      <td>0.833045</td>\n",
       "      <td>-1.375424</td>\n",
       "      <td>276.273282</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>283.015223</td>\n",
       "      <td>275.484973</td>\n",
       "      <td>0.332222</td>\n",
       "      <td>0</td>\n",
       "      <td>0.237348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29181</th>\n",
       "      <td>5.863604</td>\n",
       "      <td>44.371453</td>\n",
       "      <td>2020-08-11</td>\n",
       "      <td>3.482120</td>\n",
       "      <td>201.169355</td>\n",
       "      <td>271.491935</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.660000</td>\n",
       "      <td>0.524723</td>\n",
       "      <td>0.301766</td>\n",
       "      <td>-0.870711</td>\n",
       "      <td>292.560683</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>306.791210</td>\n",
       "      <td>292.312144</td>\n",
       "      <td>0.322469</td>\n",
       "      <td>0</td>\n",
       "      <td>0.139633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6624 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              x          y       time    density   First_Day    Last_Day  \\\n",
       "22558  4.337576  44.430909 2018-08-17  65.063034  207.411290  279.903226   \n",
       "22559  4.337576  44.430909 2018-08-18  65.063034  208.483871  280.709677   \n",
       "22560  4.337576  44.430909 2018-08-19  65.063034  209.556452  281.516129   \n",
       "22561  4.337576  44.430909 2018-08-20  65.063034  210.629032  282.322581   \n",
       "22562  4.337576  44.430909 2018-08-21  65.063034  211.701613  283.129032   \n",
       "...         ...        ...        ...        ...         ...         ...   \n",
       "29177  6.368977  44.678641 2020-11-09   1.219522  303.233333  330.133333   \n",
       "29178  5.308685  43.519256 2020-05-16  62.826794  117.935484  190.032258   \n",
       "29179  4.377214  44.787643 2020-02-13   3.489132   35.017241   87.482759   \n",
       "29180  5.724875  44.193087 2020-02-05   1.912674   15.413793   77.206897   \n",
       "29181  5.863604  44.371453 2020-08-11   3.482120  201.169355  271.491935   \n",
       "\n",
       "       Burn_Date  FireMask  ET_500m_mean  Fpar_500m_mean  u10_mean  v10_mean  \\\n",
       "22558        0.0       1.0     16.230000        0.584072  0.419922 -1.000133   \n",
       "22559        0.0       1.0     16.100002        0.585918  0.456385 -1.454020   \n",
       "22560        0.0       1.0     15.850001        0.587551  0.431329 -1.913773   \n",
       "22561        0.0       1.0     15.600000        0.588971  0.459216 -1.988419   \n",
       "22562        0.0       1.0     15.350000        0.590178  0.499901 -2.060565   \n",
       "...          ...       ...           ...             ...       ...       ...   \n",
       "29177        0.0       0.0   3276.500000        0.210865 -0.744626 -0.512833   \n",
       "29178        0.0       0.0     22.600000        0.600984 -0.620881  0.019610   \n",
       "29179        0.0       0.0   3276.500000        0.407908  1.204479 -0.460502   \n",
       "29180        0.0       0.0      7.139999        0.514080  0.833045 -1.375424   \n",
       "29181        0.0       0.0     19.660000        0.524723  0.301766 -0.870711   \n",
       "\n",
       "         t2m_mean   tp_mean  LST_Day_1km_mean  LST_Night_1km_mean  \\\n",
       "22558  293.199289  0.004510        301.407863          289.563687   \n",
       "22559  292.898217  0.004733        301.139173          289.720516   \n",
       "22560  292.856045  0.004273        301.387495          290.000703   \n",
       "22561  293.172901  0.001606        301.535495          290.404703   \n",
       "22562  293.591260  0.001606        301.630000          290.748497   \n",
       "...           ...       ...               ...                 ...   \n",
       "29177  274.738078  0.000372        282.273217          272.741976   \n",
       "29178  288.015295  0.002085        296.151572          288.335298   \n",
       "29179  276.489115  0.000287        279.911783          275.180564   \n",
       "29180  276.273282  0.001132        283.015223          275.484973   \n",
       "29181  292.560683  0.000054        306.791210          292.312144   \n",
       "\n",
       "       _1_km_16_days_EVI_mean  FireMask_pred  FireMask_proba  \n",
       "22558                0.380487              0        0.286378  \n",
       "22559                0.382837              0        0.286378  \n",
       "22560                0.385432              0        0.286378  \n",
       "22561                0.388272              0        0.302589  \n",
       "22562                0.391357              0        0.302589  \n",
       "...                       ...            ...             ...  \n",
       "29177                0.142431              0        0.143328  \n",
       "29178                0.364459              0        0.211722  \n",
       "29179                0.192178              1        0.644748  \n",
       "29180                0.332222              0        0.237348  \n",
       "29181                0.322469              0        0.139633  \n",
       "\n",
       "[6624 rows x 19 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the predictions and the probabilities to the dataframe\n",
    "df_test['FireMask_pred'] = df_pred['FireMask_pred']\n",
    "df_test['FireMask_proba'] = df_pred['FireMask_proba']\n",
    "df_test\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('tamere_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a5e4a169523c97082b9a61f1d5b30181bb70bd95bb60f5f4a5e683d694ee4c37"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
